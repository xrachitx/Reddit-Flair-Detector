{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomialNaiveBayes(X_train, X_test, y_train, y_test):\n",
    "    nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "\n",
    "    tempNB = nb.fit(X_train, y_train)\n",
    "    yPred = nb.predict(X_test)\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X_train, X_test, y_train, y_test):\n",
    "    logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression(n_jobs=1, C=1e9)),\n",
    "                   ])\n",
    "    tempLR = logreg.fit(X_train, y_train)\n",
    "    yPred = logreg.predict(X_test)\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(X_train, X_test, y_train, y_test):\n",
    "    ranfor = Pipeline([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 42)),\n",
    "                      ])\n",
    "    tempRM = ranfor.fit(X_train, y_train)\n",
    "    yPred = ranfor.predict(X_test)\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiLayerPerceptron(X_train, X_test, y_train, y_test):\n",
    "    mlp= Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MLPClassifier(hidden_layer_sizes=(30,30,30))),\n",
    "                     ])\n",
    "    tempMLP = mlp.fit(X_train, y_train)\n",
    "    yPred = mlp.predict(X_test)\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySVM(X_train, X_test, y_train, y_test):\n",
    "    svmNew = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', svm.SVC(kernel='linear', C=1.0)),\n",
    "                   ])\n",
    "    SVM = svmNew.fit(X_train, y_train)\n",
    "    yPred = svmNew.predict(X_test)\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching and Splitting Cleaned Data into Test and Train Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = flairs= [\"Scheduled\",\"Politics\",\"Photography\",\"Policy/Economy\",\"AskIndia\",\"Sports\",\n",
    "         \"Non-Political\",\"Science/Technology\",\"Food\",\"Business/Finance\",\"Coronavirus\"]\n",
    "data = pd.read_csv('../data/cleansedData300.csv')\n",
    "data[\"combined\"] = data.title.astype(\"str\")+\" \"+ data.url.astype(\"str\")+\" \"+ data.author.astype(\"str\")+\" \"+data.authors.astype(\"str\")+\" \"+ data.comments.astype(\"str\")\n",
    "y = data.flair\n",
    "X = data.combined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Nomial Naive Bayes Accuracy:  0.6666666666666666\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.50      0.68      0.58        28\n",
      "          Politics       0.70      0.48      0.57        29\n",
      "       Photography       0.65      0.81      0.72        32\n",
      "    Policy/Economy       0.67      0.63      0.65        19\n",
      "          AskIndia       0.33      0.21      0.26        24\n",
      "            Sports       0.84      0.93      0.88        28\n",
      "     Non-Political       0.42      0.59      0.49        17\n",
      "Science/Technology       0.62      0.67      0.64        24\n",
      "              Food       0.96      1.00      0.98        27\n",
      "  Business/Finance       0.79      0.60      0.68        25\n",
      "       Coronavirus       1.00      0.57      0.73        14\n",
      "\n",
      "          accuracy                           0.67       267\n",
      "         macro avg       0.68      0.65      0.65       267\n",
      "      weighted avg       0.68      0.67      0.66       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accNB = multinomialNaiveBayes(X_train, X_test, y_train, y_test)\n",
    "print(\"Multi-Nomial Naive Bayes Accuracy: \",accuracy_score(accNB, y_test))\n",
    "print()\n",
    "print(classification_report(y_test, accNB,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  0.6367041198501873\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.44      0.54      0.48        28\n",
      "          Politics       0.68      0.52      0.59        29\n",
      "       Photography       0.69      0.69      0.69        32\n",
      "    Policy/Economy       0.52      0.63      0.57        19\n",
      "          AskIndia       0.41      0.38      0.39        24\n",
      "            Sports       0.82      0.82      0.82        28\n",
      "     Non-Political       0.42      0.59      0.49        17\n",
      "Science/Technology       0.67      0.58      0.62        24\n",
      "              Food       0.90      1.00      0.95        27\n",
      "  Business/Finance       0.68      0.60      0.64        25\n",
      "       Coronavirus       0.89      0.57      0.70        14\n",
      "\n",
      "          accuracy                           0.64       267\n",
      "         macro avg       0.65      0.63      0.63       267\n",
      "      weighted avg       0.65      0.64      0.64       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accLR = logisticRegression(X_train, X_test, y_train, y_test)\n",
    "print(\"Logistic Regression Accuracy: \",accuracy_score(accLR, y_test))\n",
    "print()\n",
    "print(classification_report(y_test, accLR,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.5655430711610487\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.49      0.68      0.57        28\n",
      "          Politics       0.44      0.41      0.43        29\n",
      "       Photography       0.51      0.81      0.63        32\n",
      "    Policy/Economy       0.26      0.26      0.26        19\n",
      "          AskIndia       1.00      0.04      0.08        24\n",
      "            Sports       0.54      0.96      0.69        28\n",
      "     Non-Political       0.62      0.29      0.40        17\n",
      "Science/Technology       0.79      0.46      0.58        24\n",
      "              Food       1.00      1.00      1.00        27\n",
      "  Business/Finance       0.48      0.48      0.48        25\n",
      "       Coronavirus       1.00      0.43      0.60        14\n",
      "\n",
      "          accuracy                           0.57       267\n",
      "         macro avg       0.65      0.53      0.52       267\n",
      "      weighted avg       0.63      0.57      0.53       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accRF = randomForest(X_train, X_test, y_train, y_test)\n",
    "print(\"Random Forest Accuracy: \",accuracy_score(accRF, y_test))\n",
    "print()\n",
    "print(classification_report(y_test, accRF,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Layer Perceptron Accuracy:  0.5205992509363296\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.38      0.21      0.27        28\n",
      "          Politics       0.64      0.24      0.35        29\n",
      "       Photography       0.68      0.53      0.60        32\n",
      "    Policy/Economy       0.46      0.68      0.55        19\n",
      "          AskIndia       0.26      0.29      0.27        24\n",
      "            Sports       0.81      0.61      0.69        28\n",
      "     Non-Political       0.26      0.71      0.37        17\n",
      "Science/Technology       0.61      0.46      0.52        24\n",
      "              Food       1.00      1.00      1.00        27\n",
      "  Business/Finance       0.35      0.52      0.42        25\n",
      "       Coronavirus       0.90      0.64      0.75        14\n",
      "\n",
      "          accuracy                           0.52       267\n",
      "         macro avg       0.58      0.54      0.53       267\n",
      "      weighted avg       0.58      0.52      0.53       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accMLP = multiLayerPerceptron(X_train, X_test, y_train, y_test)\n",
    "print(\"Multi Layer Perceptron Accuracy: \",accuracy_score(accMLP, y_test))\n",
    "print()\n",
    "print(classification_report(y_test, accMLP,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy:  0.6367041198501873\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.38      0.21      0.27        28\n",
      "          Politics       0.64      0.24      0.35        29\n",
      "       Photography       0.68      0.53      0.60        32\n",
      "    Policy/Economy       0.46      0.68      0.55        19\n",
      "          AskIndia       0.26      0.29      0.27        24\n",
      "            Sports       0.81      0.61      0.69        28\n",
      "     Non-Political       0.26      0.71      0.37        17\n",
      "Science/Technology       0.61      0.46      0.52        24\n",
      "              Food       1.00      1.00      1.00        27\n",
      "  Business/Finance       0.35      0.52      0.42        25\n",
      "       Coronavirus       0.90      0.64      0.75        14\n",
      "\n",
      "          accuracy                           0.52       267\n",
      "         macro avg       0.58      0.54      0.53       267\n",
      "      weighted avg       0.58      0.52      0.53       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accSVM = mySVM(X_train, X_test, y_train, y_test)\n",
    "print(\"SVM Accuracy: \",accuracy_score(accSVM, y_test))\n",
    "print()\n",
    "print(classification_report(y_test, accMLP,target_names=flairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Naive Bayes Model since it was the best of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "           ('tfidf', TfidfTransformer()),\n",
    "           ('clf', MultinomialNB()),\n",
    "          ])\n",
    "\n",
    "tempNB = nb.fit(X_train, y_train)\n",
    "pickle.dump(tempNB,open(\"../data/finalModel.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
